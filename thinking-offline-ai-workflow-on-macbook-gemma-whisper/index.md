# [心得] 無網路 AI 工作流：在 MacBook 上運行 Gemma 與 Whisper


本文記錄了如何在 MacBook 上透過 `LM Studio` 和 `Whisper` 建立一個完全離線的 AI 工作流程，實現本地端的模型推論與語音辨識。

<!--more-->

## 使用 LM Studio 做離線大語言模型推論

-   **目標**：在無網路環境下，能在自己的電腦完成大語言模型的推論。
-   **電腦設備**：`MacBook Air M4`，`16GB` 記憶體。
-   **選用模型**：`google/gemma-3-12b`，模型大小約 8GB。
-   **性能**：
    -   `16GB` 記憶體足夠使用該模型。
    -   每秒輸出約 `15個 Token`，使用體感普通流暢。
-   **模型特色**：
    -   除了文字聊天，還支援**視覺模型**功能，可以辨識照片中的物體。
    -   支援 **function call** 功能，透過事先寫好的 Python 程式呼叫功能。
-   **使用方式**：
    -   `LM Studio` 可以用聊天模式直接互動或分析圖片內容。
    -   也能架設在 `localhost`，透過 Python 程式與模型溝通。
-   **擴充套件**：
    -   嘗試搭配 `Roocode`（VSCODE 插件）。
    -   預設 Token 上限不足，調整到 `13萬` 後功能正常。
    -   已成功實現 **Tool Use(Function call)**、**Vision**、**Roocode** 等功能。
-   **總結**：
    -   未來可在無網路狀態下完成多項任務，品質與速度尚可。

---

## Whisper 語音轉文字嘗試

-   **嘗試工具**：
    -   **MacWhisper**（Mac 專用，免費版含 `small` 模型）。
    -   過去使用 Google Colab 上的 `Large V2` 模型，翻譯準確率約 `98%` 以上，但處理速度較慢。
-   **模型大小**：
    -   `Large V2` 約 2GB?，下載與運算耗時較長。
    -   `Small` 模型約 400MB+，處理快速，適合快速語音轉文字。
-   **Whisper 特性**：
    -   會附帶**時間軸資訊**。
-   **本地化使用**：
    -   除 `MacWhisper` 外，發現 Python 版本也可本地執行，且轉出品質相同。
    -   未來語音轉文字可完全在本地環境完成。
-   **MacWhisper 操作體驗**：
    -   可單擊右側 `command` 鍵開始錄音，再點擊一次結束錄音。
    -   不需網路，全靠下載好的 `small` 模型處理，使用非常方便。

---

## **總結:**

目前已成功在本地環境中實現了**大語言模型推論** (`LM Studio` + `Gemma`) 和**語音轉文字**功能 (`MacWhisper`/`Python Whisper`)。 所有操作均無需網路連接，依賴自行下載的模型。

## 心得

-   為什麼要全部在本地運行還不太確定，但先記錄下來。
-   本地運行帶來的**便利性**與**隱私保障**是很重要的考量。

下一步開始研究M8N

## AndroidFileTransfer.dmg

傳檔案工具，裝完後，手機與電腦重開機後才可以用
